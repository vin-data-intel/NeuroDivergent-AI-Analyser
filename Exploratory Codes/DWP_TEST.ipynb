{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efc0b4d3-048e-4e49-835b-f79e4ebff9ac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Threshold----\n",
      "cort-maxprob-thr25-2mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of volumes in the 4D image for file USM_0050446 :  236\n",
      "****************************\n",
      "USM_0050446  -->  n_regions -->  236 n_time_points -->  48\n",
      "****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 2/1000 [00:20<2:54:00, 10.46s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Data List -----> \n",
      "Learning Rate -->  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:19,  4.96it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:00<00:06, 14.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6519943475723267\n",
      "Epoch: 2, Loss: 0.6239675283432007\n",
      "Epoch: 3, Loss: 0.5927113890647888\n",
      "Epoch: 4, Loss: 0.5578501224517822\n",
      "Epoch: 5, Loss: 0.519758403301239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 7/100 [00:00<00:04, 19.30it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:00<00:04, 20.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.4789934456348419\n",
      "Epoch: 7, Loss: 0.43625032901763916\n",
      "Epoch: 8, Loss: 0.3923397660255432\n",
      "Epoch: 9, Loss: 0.3481598198413849\n",
      "Epoch: 10, Loss: 0.3046555519104004\n",
      "Epoch: 11, Loss: 0.2627648711204529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 14/100 [00:00<00:03, 23.74it/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:00<00:03, 25.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.22335362434387207\n",
      "Epoch: 13, Loss: 0.18714982271194458\n",
      "Epoch: 14, Loss: 0.1546863317489624\n",
      "Epoch: 15, Loss: 0.12626507878303528\n",
      "Epoch: 16, Loss: 0.10194984823465347\n",
      "Epoch: 17, Loss: 0.08158980309963226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 20/100 [00:00<00:03, 24.94it/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:01<00:02, 30.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 0.06486798077821732\n",
      "Epoch: 19, Loss: 0.0513605959713459\n",
      "Epoch: 20, Loss: 0.04059751331806183\n",
      "Epoch: 21, Loss: 0.032110415399074554\n",
      "Epoch: 22, Loss: 0.025467440485954285\n",
      "Epoch: 23, Loss: 0.020291481167078018\n",
      "Epoch: 24, Loss: 0.016266483813524246\n",
      "Epoch: 25, Loss: 0.01313568465411663\n",
      "Epoch: 26, Loss: 0.010695278644561768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 31/100 [00:01<00:01, 36.77it/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:01<00:01, 40.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 0.00878635048866272\n",
      "Epoch: 28, Loss: 0.00728604756295681\n",
      "Epoch: 29, Loss: 0.00610013073310256\n",
      "Epoch: 30, Loss: 0.0051570250652730465\n",
      "Epoch: 31, Loss: 0.004401875659823418\n",
      "Epoch: 32, Loss: 0.0037930700927972794\n",
      "Epoch: 33, Loss: 0.0032987960148602724\n",
      "Epoch: 34, Loss: 0.002894618781283498\n",
      "Epoch: 35, Loss: 0.002561979927122593\n",
      "Epoch: 36, Loss: 0.002286202972754836\n",
      "Epoch: 37, Loss: 0.002056271303445101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 43/100 [00:01<00:01, 45.29it/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:01<00:01, 44.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Loss: 0.0018630543490871787\n",
      "Epoch: 39, Loss: 0.0016999093350023031\n",
      "Epoch: 40, Loss: 0.0015613758005201817\n",
      "Epoch: 41, Loss: 0.0014429405564442277\n",
      "Epoch: 42, Loss: 0.001341396477073431\n",
      "Epoch: 43, Loss: 0.0012536532012745738\n",
      "Epoch: 44, Loss: 0.001177571015432477\n",
      "Epoch: 45, Loss: 0.001111366436816752\n",
      "Epoch: 46, Loss: 0.001053493469953537\n",
      "Epoch: 47, Loss: 0.0010027624666690826\n",
      "Epoch: 48, Loss: 0.0009579836623743176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      " 54%|█████▍    | 54/100 [00:01<00:00, 47.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Loss: 0.0009184433147311211\n",
      "Epoch: 50, Loss: 0.0008834273321554065\n",
      "Epoch: 51, Loss: 0.0008522216230630875\n",
      "Epoch: 52, Loss: 0.0008244690834544599\n",
      "Epoch: 53, Loss: 0.0007995745982043445\n",
      "Epoch: 54, Loss: 0.0007773000397719443\n",
      "Epoch: 55, Loss: 0.0007572882459498942\n",
      "Epoch: 56, Loss: 0.0007391819381155074\n",
      "Epoch: 57, Loss: 0.0007228621980175376\n",
      "Epoch: 58, Loss: 0.0007082099909894168\n",
      "Epoch: 59, Loss: 0.0006948678637854755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 60/100 [00:01<00:00, 48.38it/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:01<00:00, 51.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Loss: 0.0006827168981544673\n",
      "Epoch: 61, Loss: 0.0006716379430145025\n",
      "Epoch: 62, Loss: 0.0006615119054913521\n",
      "Epoch: 63, Loss: 0.0006523388437926769\n",
      "Epoch: 64, Loss: 0.0006438804557546973\n",
      "Epoch: 65, Loss: 0.000636255950666964\n",
      "Epoch: 66, Loss: 0.0006291079334914684\n",
      "Epoch: 67, Loss: 0.0006225554971024394\n",
      "Epoch: 68, Loss: 0.0006165986997075379\n",
      "Epoch: 69, Loss: 0.000610999355558306\n",
      "Epoch: 70, Loss: 0.0006058764411136508\n",
      "Epoch: 71, Loss: 0.0006011109799146652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|███████▏  | 72/100 [00:01<00:00, 51.57it/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:02<00:00, 49.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, Loss: 0.0005965837044641376\n",
      "Epoch: 73, Loss: 0.0005925330333411694\n",
      "Epoch: 74, Loss: 0.0005886013968847692\n",
      "Epoch: 75, Loss: 0.0005850272136740386\n",
      "Epoch: 76, Loss: 0.0005816913326270878\n",
      "Epoch: 77, Loss: 0.000578474544454366\n",
      "Epoch: 78, Loss: 0.0005754960584454238\n",
      "Epoch: 79, Loss: 0.0005727558163926005\n",
      "Epoch: 80, Loss: 0.0005700155161321163\n",
      "Epoch: 81, Loss: 0.0005675135762430727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 83/100 [00:02<00:00, 48.75it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:02<00:00, 48.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82, Loss: 0.0005651307292282581\n",
      "Epoch: 83, Loss: 0.0005628670332953334\n",
      "Epoch: 84, Loss: 0.0005607224884442985\n",
      "Epoch: 85, Loss: 0.0005586970364674926\n",
      "Epoch: 86, Loss: 0.0005567907355725765\n",
      "Epoch: 87, Loss: 0.0005548844928853214\n",
      "Epoch: 88, Loss: 0.0005530973430722952\n",
      "Epoch: 89, Loss: 0.000551310193259269\n",
      "Epoch: 90, Loss: 0.0005496421363204718\n",
      "Epoch: 91, Loss: 0.0005479741375893354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 93/100 [00:02<00:00, 47.45it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:02<00:00, 39.07it/s][A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92, Loss: 0.000546425289940089\n",
      "Epoch: 93, Loss: 0.0005449955351650715\n",
      "Epoch: 94, Loss: 0.000543446687515825\n",
      "Epoch: 95, Loss: 0.0005420169327408075\n",
      "Epoch: 96, Loss: 0.0005407063290476799\n",
      "Epoch: 97, Loss: 0.0005392765742726624\n",
      "Epoch: 98, Loss: 0.0005379660287871957\n",
      "Epoch: 99, Loss: 0.000536655425094068\n",
      "Epoch: 100, Loss: 0.0005353448214009404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/112 [00:03<06:15,  3.38s/it]\u001b[A\n",
      "  2%|▏         | 2/112 [00:06<06:08,  3.35s/it]\u001b[A\n",
      "  3%|▎         | 3/112 [00:09<05:26,  3.00s/it]\u001b[A\n",
      "  4%|▎         | 4/112 [00:11<04:51,  2.70s/it]\u001b[A\n",
      "  4%|▍         | 5/112 [00:13<04:22,  2.46s/it]\u001b[A\n",
      "  5%|▌         | 6/112 [00:15<03:54,  2.21s/it]\u001b[A\n",
      "  6%|▋         | 7/112 [00:16<03:32,  2.03s/it]\u001b[A\n",
      "  8%|▊         | 9/112 [00:20<03:23,  1.98s/it]\u001b[A\n",
      "  9%|▉         | 10/112 [00:22<03:05,  1.82s/it]\u001b[A\n",
      " 10%|▉         | 11/112 [00:23<02:50,  1.69s/it]\u001b[A\n",
      " 11%|█         | 12/112 [00:26<03:20,  2.01s/it]\u001b[A\n",
      " 12%|█▏        | 13/112 [00:30<04:07,  2.50s/it]\u001b[A\n",
      " 12%|█▎        | 14/112 [00:32<04:13,  2.59s/it]\u001b[A\n",
      " 13%|█▎        | 15/112 [00:34<03:54,  2.42s/it]\u001b[A\n",
      " 14%|█▍        | 16/112 [00:37<03:45,  2.35s/it]\u001b[A\n",
      " 15%|█▌        | 17/112 [00:40<04:06,  2.60s/it]\u001b[A\n",
      " 16%|█▌        | 18/112 [00:41<03:37,  2.31s/it]\u001b[A\n",
      " 17%|█▋        | 19/112 [00:43<03:17,  2.12s/it]\u001b[A\n",
      " 18%|█▊        | 20/112 [00:46<03:49,  2.50s/it]\u001b[A\n",
      " 20%|█▉        | 22/112 [00:49<02:44,  1.83s/it]\u001b[A\n",
      " 21%|██        | 23/112 [00:51<02:58,  2.00s/it]\u001b[A\n",
      " 21%|██▏       | 24/112 [00:53<02:55,  2.00s/it]\u001b[A\n",
      " 23%|██▎       | 26/112 [00:55<02:22,  1.66s/it]\u001b[A\n",
      " 24%|██▍       | 27/112 [00:57<02:16,  1.60s/it]\u001b[A\n",
      " 25%|██▌       | 28/112 [01:01<03:02,  2.18s/it]\u001b[A\n",
      " 27%|██▋       | 30/112 [01:03<02:22,  1.74s/it]\u001b[A\n",
      " 28%|██▊       | 31/112 [01:05<02:26,  1.81s/it]\u001b[A\n",
      " 29%|██▊       | 32/112 [01:06<02:16,  1.70s/it]\u001b[A\n",
      " 30%|███       | 34/112 [01:11<02:25,  1.87s/it]\u001b[A\n",
      " 31%|███▏      | 35/112 [01:14<02:58,  2.31s/it]\u001b[A\n",
      " 32%|███▏      | 36/112 [01:17<03:01,  2.38s/it]\u001b[A\n",
      " 34%|███▍      | 38/112 [01:19<02:17,  1.85s/it]\u001b[A\n",
      " 35%|███▍      | 39/112 [01:21<02:20,  1.93s/it]\u001b[A\n",
      " 36%|███▌      | 40/112 [01:23<02:08,  1.78s/it]\u001b[A\n",
      " 37%|███▋      | 41/112 [01:25<02:17,  1.93s/it]\u001b[A\n",
      " 38%|███▊      | 42/112 [01:27<02:18,  1.98s/it]\u001b[A\n",
      " 38%|███▊      | 43/112 [01:29<02:04,  1.80s/it]\u001b[A\n",
      " 40%|████      | 45/112 [01:30<01:21,  1.22s/it]\u001b[A\n",
      " 41%|████      | 46/112 [01:31<01:22,  1.25s/it]\u001b[A\n",
      " 42%|████▏     | 47/112 [01:33<01:29,  1.37s/it]\u001b[A\n",
      " 43%|████▎     | 48/112 [01:34<01:32,  1.45s/it]\u001b[A\n",
      " 44%|████▍     | 49/112 [01:38<02:14,  2.13s/it]\u001b[A\n",
      " 45%|████▍     | 50/112 [01:42<02:33,  2.48s/it]\u001b[A\n",
      " 46%|████▌     | 51/112 [01:44<02:33,  2.52s/it]\u001b[A\n",
      " 46%|████▋     | 52/112 [01:46<02:11,  2.19s/it]\u001b[A\n",
      " 48%|████▊     | 54/112 [01:50<02:01,  2.09s/it]\u001b[A\n",
      " 49%|████▉     | 55/112 [01:52<02:11,  2.31s/it]\u001b[A\n",
      " 50%|█████     | 56/112 [01:55<02:10,  2.32s/it]\u001b[A\n",
      " 51%|█████     | 57/112 [01:57<02:02,  2.23s/it]\u001b[A\n",
      " 52%|█████▏    | 58/112 [01:58<01:42,  1.89s/it]\u001b[A\n",
      " 53%|█████▎    | 59/112 [02:02<02:12,  2.50s/it]\u001b[A\n",
      " 54%|█████▎    | 60/112 [02:03<01:52,  2.17s/it]\u001b[A\n",
      " 55%|█████▌    | 62/112 [02:06<01:25,  1.71s/it]\u001b[A\n",
      " 56%|█████▋    | 63/112 [02:07<01:26,  1.77s/it]\u001b[A\n",
      " 58%|█████▊    | 65/112 [02:12<01:29,  1.90s/it]\u001b[A\n",
      " 60%|█████▉    | 67/112 [02:14<01:10,  1.56s/it]\u001b[A\n",
      " 62%|██████▏   | 69/112 [02:17<01:06,  1.55s/it]\u001b[A\n",
      " 62%|██████▎   | 70/112 [02:18<01:03,  1.51s/it]\u001b[A\n",
      " 64%|██████▍   | 72/112 [02:20<00:53,  1.35s/it]\u001b[A\n",
      " 65%|██████▌   | 73/112 [02:22<00:59,  1.52s/it]\u001b[A\n",
      " 66%|██████▌   | 74/112 [02:26<01:18,  2.06s/it]\u001b[A\n",
      " 67%|██████▋   | 75/112 [02:29<01:22,  2.23s/it]\u001b[A\n",
      " 68%|██████▊   | 76/112 [02:31<01:17,  2.16s/it]\u001b[A\n",
      " 69%|██████▉   | 77/112 [02:32<01:07,  1.93s/it]\u001b[A\n",
      " 70%|██████▉   | 78/112 [02:34<01:03,  1.87s/it]\u001b[A\n",
      " 71%|███████   | 79/112 [02:36<01:02,  1.90s/it]\u001b[A\n",
      " 71%|███████▏  | 80/112 [02:37<00:52,  1.63s/it]\u001b[A\n",
      " 73%|███████▎  | 82/112 [02:39<00:40,  1.35s/it]\u001b[A\n",
      " 74%|███████▍  | 83/112 [02:41<00:43,  1.51s/it]\u001b[A\n",
      " 75%|███████▌  | 84/112 [02:44<00:51,  1.82s/it]\u001b[A\n",
      " 76%|███████▌  | 85/112 [02:48<01:04,  2.37s/it]\u001b[A\n",
      " 77%|███████▋  | 86/112 [02:49<00:54,  2.09s/it]\u001b[A\n",
      " 78%|███████▊  | 87/112 [02:51<00:51,  2.07s/it]\u001b[A\n",
      " 79%|███████▊  | 88/112 [02:54<00:55,  2.30s/it]\u001b[A\n",
      " 79%|███████▉  | 89/112 [02:55<00:46,  2.03s/it]\u001b[A\n",
      " 80%|████████  | 90/112 [02:57<00:44,  2.01s/it]\u001b[A\n",
      " 81%|████████▏ | 91/112 [02:59<00:43,  2.07s/it]\u001b[A\n",
      " 82%|████████▏ | 92/112 [03:01<00:41,  2.05s/it]\u001b[A\n",
      " 83%|████████▎ | 93/112 [03:05<00:50,  2.65s/it]\u001b[A\n",
      " 84%|████████▍ | 94/112 [03:06<00:38,  2.15s/it]\u001b[A\n",
      " 85%|████████▍ | 95/112 [03:09<00:40,  2.39s/it]\u001b[A\n",
      " 86%|████████▌ | 96/112 [03:14<00:47,  2.94s/it]\u001b[A\n",
      " 87%|████████▋ | 97/112 [03:16<00:41,  2.76s/it]\u001b[A\n",
      " 88%|████████▊ | 98/112 [03:18<00:35,  2.53s/it]\u001b[A\n",
      " 88%|████████▊ | 99/112 [03:20<00:32,  2.49s/it]\u001b[A\n",
      " 89%|████████▉ | 100/112 [03:24<00:35,  2.97s/it]\u001b[A\n",
      " 91%|█████████ | 102/112 [03:27<00:22,  2.24s/it]\u001b[A\n",
      " 93%|█████████▎| 104/112 [03:29<00:14,  1.77s/it]\u001b[A\n",
      " 94%|█████████▍| 105/112 [03:33<00:15,  2.21s/it]\u001b[A\n",
      " 95%|█████████▍| 106/112 [03:36<00:13,  2.33s/it]\u001b[A\n",
      " 96%|█████████▌| 107/112 [03:38<00:11,  2.30s/it]\u001b[A\n",
      " 96%|█████████▋| 108/112 [03:39<00:07,  1.94s/it]\u001b[A\n",
      " 97%|█████████▋| 109/112 [03:41<00:06,  2.06s/it]\u001b[A\n",
      " 98%|█████████▊| 110/112 [03:45<00:05,  2.50s/it]\u001b[A\n",
      " 99%|█████████▉| 111/112 [03:49<00:02,  2.89s/it]\u001b[A\n",
      "100%|██████████| 112/112 [03:51<00:00,  2.06s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/96 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/4 [04:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "process_row() missing 1 required positional argument: 'time_series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j0/d6kb3mqd2rdcd0jvfxnzslxw0000gn/T/ipykernel_86543/3909979459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccessful_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_series_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccessful_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccessful_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mgraph_data_test_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccessful_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    607\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: process_row() missing 1 required positional argument: 'time_series'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import input_data, datasets\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from fastdtw import fastdtw\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.nn import BatchNorm1d, Dropout\n",
    "import os\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pprint\n",
    "# Ignore all warnings (not recommended unless you know what you are doing)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "            \n",
    "\n",
    "\n",
    "train_data_eda = \"test_dwp_train_eda/\"\n",
    "os.makedirs(train_data_eda, exist_ok=True)\n",
    "\n",
    "test_result_dir = \"test_dwp_test_result/\"\n",
    "os.makedirs(test_result_dir, exist_ok=True)\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = pd.read_csv(r\"/Users/vinoth/PycharmProjects/paper_implementation/Dataset/source/mri_images/ABIDE_pcp/Phenotypic_V1_0b_preprocessed1.csv\")\n",
    "csv_file['DX_GROUP'].replace({1: 0, 2: 1}, inplace=True)\n",
    "train_df, test_df = train_test_split(csv_file, test_size=0.1, random_state=42)\n",
    "\n",
    "harvard_oxford_atlas = [\n",
    "    \"cort-maxprob-thr25-2mm\",\n",
    "    \"cort-maxprob-thr50-2mm\",\n",
    "    \"cort-prob-2mm\",\n",
    "    \"cort-maxprob-thr0-2mm\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "'''harvard_oxford_atlas = [\n",
    "    \"cort-maxprob-thr0-1mm\",\n",
    "    \"cort-maxprob-thr0-2mm\",\n",
    "    \"cort-maxprob-thr25-1mm\",\n",
    "    \"cort-maxprob-thr25-2mm\",\n",
    "    \"cort-maxprob-thr50-1mm\",\n",
    "    \"cort-maxprob-thr50-2mm\",\n",
    "    \"cort-prob-1mm\",\n",
    "    \"cort-prob-2mm\",\n",
    "    \"cortl-maxprob-thr0-1mm\",\n",
    "    \"cortl-maxprob-thr0-2mm\",\n",
    "    \"cortl-maxprob-thr25-1mm\",\n",
    "    \"cortl-maxprob-thr25-2mm\",\n",
    "    \"cortl-maxprob-thr50-1mm\",\n",
    "    \"cortl-maxprob-thr50-2mm\",\n",
    "    \"cortl-prob-1mm\",\n",
    "    \"cortl-prob-2mm\",\n",
    "    \"sub-maxprob-thr0-1mm\",\n",
    "    \"sub-maxprob-thr0-2mm\",\n",
    "    \"sub-maxprob-thr25-1mm\",\n",
    "    \"sub-maxprob-thr25-2mm\",\n",
    "    \"sub-maxprob-thr50-1mm\",\n",
    "    \"sub-maxprob-thr50-2mm\",\n",
    "    \"sub-prob-1mm\",\n",
    "    \"sub-prob-2mm\"\n",
    "]'''\n",
    "\n",
    "\n",
    "results = {}\n",
    "atlas_threshold = None\n",
    "\n",
    "for data in tqdm(harvard_oxford_atlas):\n",
    "    atlas_threshold = data\n",
    "    print(\"----Threshold----\")\n",
    "    print(atlas_threshold)\n",
    "    results[atlas_threshold] = {}\n",
    "    atlas = datasets.fetch_atlas_harvard_oxford(data)\n",
    "    masker = input_data.NiftiLabelsMasker(labels_img=atlas.maps, standardize=True)\n",
    "    mri_dir = r\"/Users/vinoth/PycharmProjects/paper_implementation/Dataset/source/mri_images/ABIDE_pcp/cpac/nofilt_noglobal/\"\n",
    "\n",
    "    # Placeholder for Graph Neural Network Data\n",
    "    graph_data_list = []\n",
    "\n",
    "    # Data Preprocessing\n",
    "    for idx, row in tqdm(enumerate(train_df.itertuples()), total=len(train_df)):\n",
    "        \n",
    "        if idx == 2:\n",
    "            break\n",
    "        # Combine the parent and nested folder paths\n",
    "        '''file_dir = os.path.join(train_data_eda, row.FILE_ID)\n",
    "        os.makedirs(file_dir, exist_ok=True)'''\n",
    "        mri_filename = os.path.join(mri_dir, row.FILE_ID + \"_func_preproc.nii.gz\")\n",
    "        \n",
    "        try:\n",
    "            mri_img = nib.load(mri_filename)\n",
    "            \n",
    "            #mri_img_dir = os.path.join(file_dir, 'mri_image')\n",
    "            #os.makedirs(mri_img_dir, exist_ok=True)\n",
    "            \n",
    "            # Select the first time point\n",
    "            first_volume = mri_img.slicer[:,:,:,0]\n",
    "            \n",
    "            image_shape = mri_img.shape\n",
    "\n",
    "            # The total number of volumes in the 4D dimension is the size of the fourth dimension\n",
    "            total_volumes = image_shape[3]\n",
    "\n",
    "            print(\"Total number of volumes in the 4D image for file \" + row.FILE_ID + \" : \", total_volumes)\n",
    "\n",
    "            '''# Plot the image\n",
    "            plotting.plot_img(first_volume, cmap='gray')  # grayscale often works well for MRIs\n",
    "            filename = os.path.join(mri_img_dir, row.FILE_ID+'_img.png')\n",
    "            plt.savefig(filename)\n",
    "            plt.close()  # Close the plot to avoid overlaps\n",
    "\n",
    "            # Plot the EPI\n",
    "            plotting.plot_epi(first_volume, display_mode='z', cut_coords=5, cmap='viridis')  # viridis is a perceptually uniform colormap\n",
    "            filename = os.path.join(mri_img_dir, row.FILE_ID+'_epi_img.png')\n",
    "            plt.savefig(filename)\n",
    "            plt.close()\n",
    "\n",
    "            # Plot the anatomy\n",
    "            plotting.plot_anat(first_volume, cmap='gray')  # grayscale again for anatomical images\n",
    "            filename = os.path.join(mri_img_dir, row.FILE_ID+'_anat_img.png')\n",
    "            plt.savefig(filename)\n",
    "            plt.close()\n",
    "\n",
    "            # Plot the statistical map\n",
    "            plotting.plot_stat_map(first_volume, bg_img=None, threshold=3.0, cmap='cold_hot')  # cold_hot is often used for stat maps\n",
    "            filename = os.path.join(mri_img_dir, row.FILE_ID+'_stat_map_img.png')\n",
    "            plt.savefig(filename)\n",
    "            plt.close()\n",
    "\n",
    "            # Plot the probabilistic atlas\n",
    "            plotting.plot_prob_atlas(mri_img, bg_img=None, colorbar=True)  # default colormap should work for probabilistic atlas\n",
    "            filename = os.path.join(mri_img_dir, row.FILE_ID+'_atlas_map_img.png')\n",
    "            plt.savefig(filename)\n",
    "            plt.close()'''\n",
    "            \n",
    "            '''from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "            def calculate_distance(i, j, time_series):\n",
    "                distance, _ = fastdtw(time_series[i, :], time_series[j, :])\n",
    "                return i, j, distance\n",
    "            \n",
    "            def wrapper(args):\n",
    "                return calculate_distance(*args)\n",
    "\n",
    "            time_series = masker.fit_transform(mri_img)\n",
    "            n_regions, n_time_points = time_series.shape\n",
    "            print(\"****************************\")\n",
    "            print(row.FILE_ID, \" --> \", \"n_regions --> \", n_regions, \"n_time_points --> \", n_time_points)\n",
    "            print(\"****************************\")\n",
    "            distance_matrix = np.zeros((n_regions, n_regions))\n",
    "\n",
    "            # Creating a list of arguments to pass to the function\n",
    "            args = [(i, j, time_series) for i in range(n_regions) for j in range(i + 1, n_regions)]\n",
    "\n",
    "            # Using ProcessPoolExecutor to execute the function in parallel\n",
    "            with ProcessPoolExecutor() as executor:\n",
    "                results = list(executor.map(wrapper, args))\n",
    "\n",
    "            # Filling the distance_matrix with the results\n",
    "            for i, j, distance in results:\n",
    "                distance_matrix[i, j] = distance_matrix[j, i] = distance\n",
    "\n",
    "            distance_matrix = distance_matrix / distance_matrix.max()\n",
    "            similarity_matrix = 1 - distance_matrix\n",
    "            threshold = 0.5\n",
    "            similarity_matrix[similarity_matrix < threshold] = 0\n",
    "            \n",
    "            print(similarity_matrix)\n",
    "            \n",
    "            G = nx.from_numpy_matrix(similarity_matrix)'''\n",
    "\n",
    "            \n",
    "            \n",
    "            from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "            def calculate_distance(i, j, time_series):\n",
    "                distance, _ = fastdtw(time_series[i, :], time_series[j, :])\n",
    "                return i, j, distance\n",
    "\n",
    "            def wrapper(args):\n",
    "                return calculate_distance(*args)\n",
    "\n",
    "            \n",
    "            time_series = masker.fit_transform(mri_img)\n",
    "            n_regions, n_time_points = time_series.shape\n",
    "            print(\"****************************\")\n",
    "            print(row.FILE_ID, \" --> \", \"n_regions --> \", n_regions, \"n_time_points --> \", n_time_points)\n",
    "            print(\"****************************\")\n",
    "            distance_matrix = np.zeros((n_regions, n_regions))\n",
    "\n",
    "            # Creating a list of arguments to pass to the function\n",
    "            args = [(i, j, time_series) for i in range(n_regions) for j in range(i + 1, n_regions)]\n",
    "\n",
    "            # Using ThreadPoolExecutor to execute the function in parallel\n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                train_thread_results = list(executor.map(wrapper, args))\n",
    "\n",
    "            # Filling the distance_matrix with the train_thread_results\n",
    "            for i, j, distance in train_thread_results:\n",
    "                distance_matrix[i, j] = distance_matrix[j, i] = distance\n",
    "\n",
    "            distance_matrix = distance_matrix / distance_matrix.max()\n",
    "            similarity_matrix = 1 - distance_matrix\n",
    "            threshold = 0.3\n",
    "            similarity_matrix[similarity_matrix < threshold] = 0\n",
    "\n",
    "            #print(similarity_matrix)\n",
    "\n",
    "            G = nx.from_numpy_matrix(similarity_matrix)\n",
    "\n",
    "                \n",
    "\n",
    "# Here you can call the function with the appropriate row\n",
    "# graph = process_time_series(row)\n",
    "\n",
    "\n",
    "\n",
    "            #if idx == 0:  # Only for the first iteration\n",
    "            # Plot the time series for the regions\n",
    "            '''plt.figure(figsize=(35, 15))\n",
    "            for i in range(min(n_regions, time_series.shape[0])):\n",
    "                plt.plot(time_series[i, :], label=f'Region {i + 1}')\n",
    "            plt.xlabel('Time point')\n",
    "            plt.ylabel('Blood Oxygen Level(BOLD) - Normalized signal')\n",
    "            plt.title('Time series of the regions')\n",
    "            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "            plt.tight_layout()'''\n",
    "        \n",
    "            # Save the plot to the existing folder\n",
    "            '''time_series_filename = row.FILE_ID+'_'+'time_series_plot.png'\n",
    "            \n",
    "            plt.savefig(os.path.join(file_dir, time_series_filename))\n",
    "            \n",
    "            plt.figure(figsize=(10, 10))\n",
    "            sns.heatmap(similarity_matrix, annot=False, cmap='turbo')\n",
    "            plt.title('Similarity Matrix')\n",
    "            similarity_matrix_adj_img_filename = row.FILE_ID + '_similarity_matrix.png'\n",
    "            plt.savefig(os.path.join(file_dir, similarity_matrix_adj_img_filename))\n",
    "            plt.close() # Close the plot\n",
    "            similarity_matrix_npy_filename = row.FILE_ID + '_similarity_matrix.npy'\n",
    "            similarity_matrix_npy_path = os.path.join(file_dir, similarity_matrix_npy_filename)\n",
    "            np.save(similarity_matrix_npy_path, similarity_matrix)'''\n",
    "\n",
    "            '''# Visualize the graph\n",
    "            plt.figure(figsize=(45, 25))\n",
    "            pos = nx.spring_layout(G)'''\n",
    "\n",
    "            # Extract the edge weights from the graph\n",
    "            weights = [G[u][v].get('weight', 1) for u, v in G.edges()]\n",
    "\n",
    "            # Normalize the weights to fit your desired range of thickness\n",
    "            normalized_weights = [5 * weight / max(weights) for weight in weights]\n",
    "\n",
    "            # Draw the edges with the thickness determined by the normalized weights\n",
    "            '''nx.draw_networkx_edges(G, pos, width=normalized_weights)\n",
    "\n",
    "            # Draw the nodes and labels\n",
    "            nx.draw_networkx_nodes(G, pos)\n",
    "            nx.draw_networkx_labels(G, pos)'''\n",
    "            \n",
    "            # Define the path and filename where you want to save the plot\n",
    "            '''graph_plot_filename = row.FILE_ID + '_graph_plot.png'\n",
    "            graph_plot_path = os.path.join(file_dir, graph_plot_filename)\n",
    "\n",
    "            # Save the plot to the specified path\n",
    "            plt.savefig(graph_plot_path)'''\n",
    "\n",
    "            edge_index = torch.tensor(list(G.edges), dtype=torch.long)\n",
    "            x = torch.tensor(time_series, dtype=torch.float)\n",
    "            y = torch.tensor([row.DX_GROUP], dtype=torch.float)\n",
    "            data = Data(x=x, edge_index=edge_index.t().contiguous(), y=y)\n",
    "            graph_data_list.append(data)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        \n",
    "    print(\"Graph Data List -----> \")\n",
    "    #print(graph_data_list)\n",
    "\n",
    "    # Neural Network Model with Regularization, Batch Normalization, and Dropout\n",
    "    class Net(torch.nn.Module):\n",
    "        def __init__(self, num_node_features, num_classes):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = GCNConv(num_node_features, 16)\n",
    "            self.bn1 = BatchNorm1d(16)\n",
    "            self.conv2 = GCNConv(16, 32)\n",
    "            self.bn2 = BatchNorm1d(32)\n",
    "            self.fc = torch.nn.Linear(32, num_classes)\n",
    "            self.dropout = Dropout(0.5)\n",
    "\n",
    "        def forward(self, data):\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = self.bn1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            x = self.bn2(x)\n",
    "            x = global_mean_pool(x, batch)\n",
    "            x = self.fc(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_features = graph_data_list[0].num_node_features\n",
    "    num_classes = 2\n",
    "    model = Net(num_features, num_classes).to(device)\n",
    "    loader = DataLoader(graph_data_list, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Hyperparameter Tuning (Example: Adjusting Learning Rate)\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    l_rate = None\n",
    "    for lr in learning_rates:\n",
    "        l_rate = str(lr)\n",
    "        results[atlas_threshold][l_rate] = {}\n",
    "        print(\"Learning Rate --> \", lr)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4) # L2 Regularization\n",
    "        for epoch in tqdm(range(100)):\n",
    "            total_loss = 0\n",
    "            model.train()\n",
    "            for data in loader:\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data)\n",
    "                loss = F.nll_loss(out, data.y.long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            print(f'Epoch: {epoch+1}, Loss: {total_loss/len(loader)}')\n",
    "        results[atlas_threshold][l_rate]['loss'] = total_loss/len(loader)\n",
    "\n",
    "        # Placeholder for time series data\n",
    "        time_series_list = []\n",
    "        successful_indices = []\n",
    "\n",
    "        # Testing Data Preprocessing\n",
    "        # for idx, row in enumerate(test_df.itertuples()):\n",
    "        for idx, row in tqdm(enumerate(test_df.itertuples()), total=len(test_df)):\n",
    "            mri_filename = os.path.join(mri_dir, row.FILE_ID + \"_func_preproc.nii.gz\")\n",
    "            try:\n",
    "                mri_img = nib.load(mri_filename)\n",
    "                time_series = masker.fit_transform(mri_img)\n",
    "                time_series_list.append(time_series)\n",
    "                successful_indices.append(idx)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        \n",
    "        # Placeholder for Graph Neural Network Data for testing\n",
    "        graph_data_test_list = []\n",
    "\n",
    "        #for idx, successful_idx in tqdm(enumerate(successful_indices, total=len(successful_indices))):\n",
    "        '''for idx, successful_idx in tqdm(enumerate(successful_indices), total=len(successful_indices)):\n",
    "            row = test_df.iloc[successful_idx]\n",
    "            time_series = time_series_list[idx]\n",
    "            n_regions = time_series.shape[0]\n",
    "            distance_matrix = np.zeros((n_regions, n_regions))\n",
    "            for i in range(n_regions):\n",
    "                for j in range(i + 1, n_regions):\n",
    "                    distance, _ = fastdtw(time_series[i, :], time_series[j, :])\n",
    "                    distance_matrix[i, j] = distance_matrix[j, i] = distance\n",
    "            distance_matrix = distance_matrix / distance_matrix.max()\n",
    "            similarity_matrix = 1 - distance_matrix\n",
    "            threshold = 0.5\n",
    "            similarity_matrix[similarity_matrix < threshold] = 0\n",
    "            G = nx.from_numpy_matrix(similarity_matrix)\n",
    "            edge_index = torch.tensor(list(G.edges), dtype=torch.long)\n",
    "            x = torch.tensor(time_series, dtype=torch.float)\n",
    "            y = torch.tensor([row.DX_GROUP], dtype=torch.float)\n",
    "            data = Data(x=x, edge_index=edge_inde'.t().contiguous(), y=y)\n",
    "            graph_data_test_list.append(data)'''\n",
    "\n",
    "        \n",
    "        \n",
    "        from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "        def calculate_distance(i, j, time_series):\n",
    "            distance, _ = fastdtw(time_series[i, :], time_series[j, :])\n",
    "            return i, j, distance\n",
    "\n",
    "        def process_row(successful_idx, time_series):\n",
    "            row = test_df.iloc[successful_idx]\n",
    "            n_regions = time_series.shape[0]\n",
    "            distance_matrix = np.zeros((n_regions, n_regions))\n",
    "\n",
    "            # Creating a list of arguments to pass to the function\n",
    "            args = [(i, j, time_series) for i in range(n_regions) for j in range(i + 1, n_regions)]\n",
    "\n",
    "            # Using ThreadPoolExecutor to execute the function in parallel\n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                thread_results = list(executor.map(calculate_distance, args))\n",
    "\n",
    "            # Filling the distance_matrix with the thread_results\n",
    "            for i, j, distance in thread_results:\n",
    "                distance_matrix[i, j] = distance_matrix[j, i] = distance\n",
    "\n",
    "            distance_matrix = distance_matrix / distance_matrix.max()\n",
    "            similarity_matrix = 1 - distance_matrix\n",
    "            threshold = 0.3\n",
    "            similarity_matrix[similarity_matrix < threshold] = 0\n",
    "            G = nx.from_numpy_matrix(similarity_matrix)\n",
    "            edge_index = torch.tensor(list(G.edges), dtype=torch.long)\n",
    "            x = torch.tensor(time_series, dtype=torch.float)\n",
    "            y = torch.tensor([row.DX_GROUP], dtype=torch.float)\n",
    "            data = Data(x=x, edge_index=edge_index.t().contiguous(), y=y)\n",
    "            return data\n",
    "\n",
    "        graph_data_test_list = []\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            args = [(successful_idx, time_series_list[idx]) for idx, successful_idx in enumerate(successful_indices)]\n",
    "            graph_data_test_list = list(tqdm(executor.map(process_row, args), total=len(successful_indices)))\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Create a data loader for testing data\n",
    "        test_loader = DataLoader(graph_data_test_list, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Testing\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for data in tqdm(test_loader):\n",
    "            data = data.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "                _, pred = output.max(dim=1)\n",
    "            all_preds.append(pred.cpu().numpy())\n",
    "            all_labels.append(data.y.cpu().numpy())\n",
    "            correct += int((pred == data.y.long()).sum())\n",
    "\n",
    "        accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')\n",
    "        \n",
    "        results[atlas_threshold][l_rate]['accuracy'] = accuracy\n",
    "\n",
    "        # Flatten the list of predictions and labels\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        \n",
    "        # Specify the parent folder\n",
    "        parent_folder = test_result_dir\n",
    "\n",
    "        # Specify the nested folder names\n",
    "        nested_folder1 = atlas_threshold\n",
    "        nested_folder2 = 'learning_rate_'+l_rate\n",
    "        \n",
    "        # Combine the parent and nested folder pa'hs\n",
    "        validation_result_dir = os.path.join(parent_folder, nested_folder1, nested_folder2)\n",
    "        \n",
    "        # Create the nested folders, including any necessary parent directories\n",
    "        os.makedirs(validation_result_dir, exist_ok=True)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, cmap='Blues', fmt=\".2%\")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix (Normalized)')\n",
    "        \n",
    "        # Save the image inside the nested folder\n",
    "        plt.savefig(os.path.join(validation_result_dir, 'confusion_matrix.png'))\n",
    "        \n",
    "        # Print actual vs predicted\n",
    "        actual_vs_predicted = pd.DataFrame({'Actual': all_labels, 'Predicted': all_preds})\n",
    "        print(actual_vs_predicted)\n",
    "\n",
    "        # Classification report\n",
    "        report = classification_report(all_labels, all_preds, target_names=['Non-Autistic', 'Autistic'], output_dict=True)\n",
    "        #print(classification_report(all_labels, all_preds, target_names=['Non-Autistic', 'Autistic']))\n",
    "        report_text = classification_report(all_labels, all_preds, target_names=['Non-Autistic', 'Autistic'])\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.text(0.01, 0.05, report_text, {'fontsize': 12}, fontproperties='monospace') # Adjust text size and position accordingly\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(validation_result_dir, 'classification_report.png'))\n",
    "        \n",
    "        with open(os.path.join(validation_result_dir, 'classification_report.txt'), 'w') as file:\n",
    "            file.write(report_text)\n",
    "  \n",
    "        # Individual class metrics\n",
    "        # Access individual values\n",
    "        non_autistic_precision = report['Non-Autistic']['precision']\n",
    "        autistic_precision = report['Autistic']['precision']\n",
    "\n",
    "        non_autistic_recall = report['Non-Autistic']['recall']\n",
    "        autistic_recall = report['Autistic']['recall']\n",
    "\n",
    "        non_autistic_f1_score = report['Non-Autistic']['f1-score']\n",
    "        autistic_f1_score = report['Autistic']['f1-score']\n",
    "\n",
    "        non_autistic_support = report['Non-Autistic']['support']\n",
    "        autistic_support = report['Autistic']['support']\n",
    "\n",
    "        '''# Aggregated metrics\n",
    "        accuracy = report['accuracy'''\n",
    "\n",
    "        macro_avg_precision = report['macro avg']['precision']\n",
    "        weighted_avg_precision = report['weighted avg']['precision']\n",
    "\n",
    "        macro_avg_recall = report['macro avg']['recall']\n",
    "        weighted_avg_recall = report['weighted avg']['recall']\n",
    "\n",
    "        macro_avg_f1_score = report['macro avg']['f1-score']\n",
    "        weighted_avg_f1_score = report['weighted avg']['f1-score']\n",
    "\n",
    "        macro_avg_support = report['macro avg']['support']\n",
    "        weighted_avg_support = report['weighted avg']['support']\n",
    "        \n",
    "        results[atlas_threshold][l_rate]['non_autistic_precision'] = non_autistic_precision\n",
    "        results[atlas_threshold][l_rate]['autistic_precision'] = autistic_precision\n",
    "        results[atlas_threshold][l_rate]['non_autistic_recall'] = non_autistic_recall\n",
    "        results[atlas_threshold][l_rate]['autistic_recall'] = autistic_recall\n",
    "        results[atlas_threshold][l_rate]['non_autistic_f1_score'] = non_autistic_f1_score\n",
    "        results[atlas_threshold][l_rate]['autistic_f1_score'] = autistic_f1_score\n",
    "        results[atlas_threshold][l_rate]['non_autistic_support'] = non_autistic_support\n",
    "        results[atlas_threshold][l_rate]['autistic_support'] = autistic_support\n",
    "        results[atlas_threshold][l_rate]['macro_avg_precision'] = macro_avg_precision\n",
    "        results[atlas_threshold][l_rate]['weighted_avg_precision'] = weighted_avg_precision\n",
    "        results[atlas_threshold][l_rate]['macro_avg_recall'] = macro_avg_recall\n",
    "        results[atlas_threshold][l_rate]['weighted_avg_recall'] = weighted_avg_recall\n",
    "        results[atlas_threshold][l_rate]['macro_avg_f1_score'] = macro_avg_f1_score\n",
    "        results[atlas_threshold][l_rate]['weighted_avg_f1_score'] = weighted_avg_f1_score\n",
    "        results[atlas_threshold][l_rate]['macro_avg_support'] = macro_avg_support\n",
    "        results[atlas_threshold][l_rate]['weighted_avg_support'] = weighted_avg_support\n",
    "        \n",
    "        atlas = None\n",
    "        l_rate = None\n",
    "        \n",
    "print(\"----Final Result----\")\n",
    "pprint.pprint(results)\n",
    "\n",
    "sorted_data = [(key, subkey, values['accuracy']) for key, subdata in results.items() for subkey, values in subdata.items()]\n",
    "sorted_data.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"----Sorted Accuracy----\")\n",
    "for key, subkey, accuracy in sorted_data:\n",
    "    print(f\"Key: {key}, Subkey: {subkey}, Accuracy: {accuracy}\")\n",
    "    \n",
    "# Create a list of tuples containing key, subkey, and corresponding details\n",
    "sorted_data = [(key, subkey, values) for key, subdata in results.items() for subkey, values in subdata.items()]\n",
    "\n",
    "# Sort the list based on the accuracy\n",
    "sorted_data.sort(key=lambda x: x[2]['accuracy'], reverse=True)\n",
    "\n",
    "# Create a new dictionary with the sorted order\n",
    "sorted_data_dict = {f\"{key}-{subkey}\": values for key, subkey, values in sorted_data}\n",
    "print(\"----Sorted Dict----\")\n",
    "pprint.pprint(sorted_data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feefab7c-937c-4511-92a0-38f2d11c4840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3e026-2bd3-414f-bd30-ea47e1804c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce732e-8a8e-466d-b790-04b3a2d861ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import input_data, datasets\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from fastdtw import fastdtw\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.nn import BatchNorm1d, Dropout\n",
    "import os\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pprint\n",
    "# Ignore all warnings (not recommended unless you know what you are doing)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "            \n",
    "\n",
    "\n",
    "'''train_data_eda = \"test_dwp_train_eda/\"\n",
    "os.makedirs(train_data_eda, exist_ok=True'''\n",
    "\n",
    "test_result_dir = \"test_dwp_test_result/\"\n",
    "os.makedirs(test_result_dir, exist_ok=True)\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = pd.read_csv(r\"/Users/vinoth/PycharmProjects/paper_implementation/Dataset/source/mri_images/ABIDE_pcp/Phenotypic_V1_0b_preprocessed1.csv\")\n",
    "csv_file['DX_GROUP'].replace({1: 0, 2: 1}, inplace=True)\n",
    "train_df, test_df = train_test_split(csv_file, test_size=0.1, random_state=42)\n",
    "\n",
    "harvard_oxford_atlas = [\n",
    "    \"cort-maxprob-thr25-2mm\"\n",
    "    #\"cort-maxprob-thr50-2mm\",\n",
    "    #\"cort-prob-2mm\",\n",
    "    #\"cort-maxprob-thr0-2mm\"\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "'''harvard_oxford_atlas = [\n",
    "    \"cort-maxprob-thr0-1mm\",\n",
    "    \"cort-maxprob-thr0-2mm\",\n",
    "    \"cort-maxprob-thr25-1mm\",\n",
    "    \"cort-maxprob-thr25-2mm\",\n",
    "    \"cort-maxprob-thr50-1mm\",\n",
    "    \"cort-maxprob-thr50-2mm\",\n",
    "    \"cort-prob-1mm\",\n",
    "    \"cort-prob-2mm\",\n",
    "    \"cortl-maxprob-thr0-1mm\",\n",
    "    \"cortl-maxprob-thr0-2mm\",\n",
    "    \"cortl-maxprob-thr25-1mm\",\n",
    "    \"cortl-maxprob-thr25-2mm\",\n",
    "    \"cortl-maxprob-thr50-1mm\",\n",
    "    \"cortl-maxprob-thr50-2mm\",\n",
    "    \"cortl-prob-1mm\",\n",
    "    \"cortl-prob-2mm\",\n",
    "    \"sub-maxprob-thr0-1mm\",\n",
    "    \"sub-maxprob-thr0-2mm\",\n",
    "    \"sub-maxprob-thr25-1mm\",\n",
    "    \"sub-maxprob-thr25-2mm\",\n",
    "    \"sub-maxprob-thr50-1mm\",\n",
    "    \"sub-maxprob-thr50-2mm\",\n",
    "    \"sub-prob-1mm\",\n",
    "    \"sub-prob-2mm\"\n",
    "]'''\n",
    "\n",
    "\n",
    "results = {}\n",
    "atlas_threshold = None\n",
    "\n",
    "for data in tqdm(harvard_oxford_atlas):\n",
    "    atlas_threshold = data\n",
    "    print(\"----Threshold----\")\n",
    "    print(atlas_threshold)\n",
    "    results[atlas_threshold] = {}\n",
    "    atlas = datasets.fetch_atlas_harvard_oxford(data)\n",
    "    masker = input_data.NiftiLabelsMasker(labels_img=atlas.maps, standardize=True)\n",
    "    mri_dir = r\"/Users/vinoth/PycharmProjects/paper_implementation/Dataset/source/mri_images/ABIDE_pcp/cpac/nofilt_noglobal/\"\n",
    "\n",
    "    # Placeholder for Graph Neural Network Data\n",
    "    graph_data_list = []\n",
    "\n",
    "    # Data Preprocessing\n",
    "    for idx, row in tqdm(enumerate(train_df.itertuples()), total=len(train_df)):\n",
    "        # Combine the parent and nested folder paths\n",
    "        #file_dir = os.path.join(train_data_eda, row.FILE_ID)\n",
    "        #os.makedirs(file_dir, exist_ok=True)\n",
    "        mri_filename = os.path.join(mri_dir, row.FILE_ID + \"_func_preproc.nii.gz\")\n",
    "        \n",
    "        try:\n",
    "            mri_img = nib.load(mri_filename)\n",
    "            \n",
    "            #mri_img_dir = os.path.join(file_dir, 'mri_image')\n",
    "            #os.makedirs(mri_img_dir, exist_ok=True)\n",
    "            \n",
    "            # Select the first time point\n",
    "            #first_volume = mri_img.slicer[:,:,:,0]\n",
    "            \n",
    "            #image_shape = mri_img.shape\n",
    "\n",
    "            # The total number of volumes in the 4D dimension is the size of the fourth dimension\n",
    "            #total_volumes = image_shape[3]\n",
    "\n",
    "            #print(\"Total number of volumes in the 4D image for file \" + row.FILE_ID + \" : \", total_volumes)\n",
    "\n",
    "            '''# Plot the image\n",
    "            plotting.plot_img(first_volume, cmap='gray')  # grayscale often works well for MRIs\n",
    "            filename = os.path.join(mri_img_dir, row.FILE_ID+'_img.png')\n",
    "            plt.savefig(filename)\n",
    "            plt.close()  # Close the plot to avoid overlaps\n",
    "\n",
    "            # Plot the EPI\n",
    "            plotting.plot_epi(first_volume, display_mode='z', cut_coords=5, cmap='viridis')  # viridis is a perceptually uniform colormap\n",
    "            filename = os.path.join(mri_img_dir, row.FILE_ID+'_epi_img.png')\n",
    "            plt.savefig(filename)\n",
    "            plt.close()\n",
    "\n",
    "            # Plot the anatomy\n",
    "            plotting.plot_anat(first_volume, cmap='gray')  # grayscale again for anatomical images\n",
    "            filename = os.path.join(mri_img_dir, row.FILE_ID+'_anat_img.png')\n",
    "            plt.savefig(filename)\n",
    "            plt.close()\n",
    "\n",
    "            # Plot the statistical map\n",
    "            plotting.plot_stat_map(first_volume, bg_img=None, threshold=3.0, cmap='cold_hot')  # cold_hot is often used for stat maps\n",
    "            filename = os.path.join(mri_img_dir, row.FILE_ID+'_stat_map_img.png')\n",
    "            plt.savefig(filename)\n",
    "            plt.close()\n",
    "\n",
    "            # Plot the probabilistic atlas\n",
    "            plotting.plot_prob_atlas(mri_img, bg_img=None, colorbar=True)  # default colormap should work for probabilistic atlas\n",
    "            filename = os.path.join(mri_img_dir, row.FILE_ID+'_atlas_map_img.png')\n",
    "            plt.savefig(filename)\n",
    "            plt.close()'''\n",
    "            \n",
    "            time_series = masker.fit_transform(mri_img)\n",
    "            n_regions, n_time_points = time_series.shape\n",
    "            '''print(\"****************************\")\n",
    "            print(row.FILE_ID, \" --> \", \"n_regions --> \", n_regions, \"n_time_points --> \", n_time_points)\n",
    "            print(\"****************************\")'''\n",
    "            distance_matrix = np.zeros((n_regions, n_regions))\n",
    "            for i in range(n_regions):\n",
    "                for j in range(i + 1, n_regions):\n",
    "                    distance, _ = fastdtw(time_series[i, :], time_series[j, :])\n",
    "                    distance_matrix[i, j] = distance_matrix[j, i] = distance\n",
    "            distance_matrix = distance_matrix / distance_matrix.max()\n",
    "            similarity_matrix = 1 - distance_matrix\n",
    "            threshold = 0.3\n",
    "            similarity_matrix[similarity_matrix < threshold] = 0\n",
    "            G = nx.from_numpy_matrix(similarity_matrix)\n",
    "\n",
    "\n",
    "            #if idx == 0:  # Only for the first iteration\n",
    "            # Plot the time series for the regions\n",
    "            '''plt.figure(figsize=(35, 15))\n",
    "            for i in range(min(n_regions, time_series.shape[0])):\n",
    "                plt.plot(time_series[i, :], label=f'Region {i + 1}')\n",
    "            plt.xlabel('Time point')\n",
    "            plt.ylabel('Blood Oxygen Level(BOLD) - Normalized signal')\n",
    "            plt.title('Time series of the regions')\n",
    "            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "            plt.tight_layout()'''\n",
    "        \n",
    "            # Save the plot to the existing folder\n",
    "            '''time_series_filename = row.FILE_ID+'_'+'time_series_plot.png'\n",
    "            \n",
    "            plt.savefig(os.path.join(file_dir, time_series_filename))\n",
    "            \n",
    "            plt.figure(figsize=(10, 10))\n",
    "            sns.heatmap(similarity_matrix, annot=False, cmap='turbo')\n",
    "            plt.title('Similarity Matrix')\n",
    "            similarity_matrix_adj_img_filename = row.FILE_ID + '_similarity_matrix.png'\n",
    "            plt.savefig(os.path.join(file_dir, similarity_matrix_adj_img_filename))\n",
    "            plt.close() # Close the plot\n",
    "            similarity_matrix_npy_filename = row.FILE_ID + '_similarity_matrix.npy'\n",
    "            similarity_matrix_npy_path = os.path.join(file_dir, similarity_matrix_npy_filename)\n",
    "            np.save(similarity_matrix_npy_path, similarity_matrix)'''\n",
    "\n",
    "            '''# Visualize the graph\n",
    "            plt.figure(figsize=(45, 25))\n",
    "            pos = nx.spring_layout(G)'''\n",
    "\n",
    "            # Extract the edge weights from the graph\n",
    "            weights = [G[u][v].get('weight', 1) for u, v in G.edges()]\n",
    "\n",
    "            # Normalize the weights to fit your desired range of thickness\n",
    "            normalized_weights = [5 * weight / max(weights) for weight in weights]\n",
    "\n",
    "            # Draw the edges with the thickness determined by the normalized weights\n",
    "            '''nx.draw_networkx_edges(G, pos, width=normalized_weights)\n",
    "\n",
    "            # Draw the nodes and labels\n",
    "            nx.draw_networkx_nodes(G, pos)\n",
    "            nx.draw_networkx_labels(G, pos)'''\n",
    "            \n",
    "            # Define the path and filename where you want to save the plot\n",
    "            '''graph_plot_filename = row.FILE_ID + '_graph_plot.png'\n",
    "            graph_plot_path = os.path.join(file_dir, graph_plot_filename)\n",
    "\n",
    "            # Save the plot to the specified path\n",
    "            plt.savefig(graph_plot_path)'''\n",
    "\n",
    "            edge_index = torch.tensor(list(G.edges), dtype=torch.long)\n",
    "            x = torch.tensor(time_series, dtype=torch.float)\n",
    "            y = torch.tensor([row.DX_GROUP], dtype=torch.float)\n",
    "            data = Data(x=x, edge_index=edge_index.t().contiguous(), y=y)\n",
    "            graph_data_list.append(data)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        \n",
    "    print(\"Graph Data List -----> \")\n",
    "    print(graph_data_list)\n",
    "\n",
    "    # Neural Network Model with Regularization, Batch Normalization, and Dropout\n",
    "    class Net(torch.nn.Module):\n",
    "        def __init__(self, num_node_features, num_classes):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = GCNConv(num_node_features, 16)\n",
    "            self.bn1 = BatchNorm1d(16)\n",
    "            self.conv2 = GCNConv(16, 32)\n",
    "            self.bn2 = BatchNorm1d(32)\n",
    "            self.fc = torch.nn.Linear(32, num_classes)\n",
    "            self.dropout = Dropout(0.5)\n",
    "\n",
    "        def forward(self, data):\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = self.bn1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            x = self.bn2(x)\n",
    "            x = global_mean_pool(x, batch)\n",
    "            x = self.fc(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_features = graph_data_list[0].num_node_features\n",
    "    num_classes = 2\n",
    "    model = Net(num_features, num_classes).to(device)\n",
    "    loader = DataLoader(graph_data_list, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Hyperparameter Tuning (Example: Adjusting Learning Rate)\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    l_rate = None\n",
    "    for lr in learning_rates:\n",
    "        l_rate = str(lr)\n",
    "        results[atlas_threshold][l_rate] = {}\n",
    "        print(\"Learning Rate --> \", lr)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4) # L2 Regularization\n",
    "        for epoch in tqdm(range(100)):\n",
    "            total_loss = 0\n",
    "            model.train()\n",
    "            for data in loader:\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data)\n",
    "                loss = F.nll_loss(out, data.y.long())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            print(f'Epoch: {epoch+1}, Loss: {total_loss/len(loader)}')\n",
    "        results[atlas_threshold][l_rate]['loss'] = total_loss/len(loader)\n",
    "\n",
    "        # Placeholder for time series data\n",
    "        time_series_list = []\n",
    "        successful_indices = []\n",
    "\n",
    "        # Testing Data Preprocessing\n",
    "        # for idx, row in enumerate(test_df.itertuples()):\n",
    "        for idx, row in tqdm(enumerate(test_df.itertuples()), total=len(test_df)):\n",
    "            mri_filename = os.path.join(mri_dir, row.FILE_ID + \"_func_preproc.nii.gz\")\n",
    "            try:\n",
    "                mri_img = nib.load(mri_filename)\n",
    "                time_series = masker.fit_transform(mri_img)\n",
    "                time_series_list.append(time_series)\n",
    "                successful_indices.append(idx)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "        \n",
    "        # Placeholder for Graph Neural Network Data for testing\n",
    "        graph_data_test_list = []\n",
    "\n",
    "        #for idx, successful_idx in tqdm(enumerate(successful_indices, total=len(successful_indices))):\n",
    "        for idx, successful_idx in tqdm(enumerate(successful_indices), total=len(successful_indices)):\n",
    "            row = test_df.iloc[successful_idx]\n",
    "            time_series = time_series_list[idx]\n",
    "            n_regions = time_series.shape[0]\n",
    "            distance_matrix = np.zeros((n_regions, n_regions))\n",
    "            for i in range(n_regions):\n",
    "                for j in range(i + 1, n_regions):\n",
    "                    distance, _ = fastdtw(time_series[i, :], time_series[j, :])\n",
    "                    distance_matrix[i, j] = distance_matrix[j, i] = distance\n",
    "            distance_matrix = distance_matrix / distance_matrix.max()\n",
    "            similarity_matrix = 1 - distance_matrix\n",
    "            threshold = 0.3\n",
    "            similarity_matrix[similarity_matrix < threshold] = 0\n",
    "            G = nx.from_numpy_matrix(similarity_matrix)\n",
    "            edge_index = torch.tensor(list(G.edges), dtype=torch.long)\n",
    "            x = torch.tensor(time_series, dtype=torch.float)\n",
    "            y = torch.tensor([row.DX_GROUP], dtype=torch.float)\n",
    "            data = Data(x=x, edge_index=edge_index.t().contiguous(), y=y)\n",
    "            graph_data_test_list.append(data)\n",
    "\n",
    "        # Create a data loader for testing data\n",
    "        test_loader = DataLoader(graph_data_test_list, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Testing\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for data in tqdm(test_loader):\n",
    "            data = data.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "                _, pred = output.max(dim=1)\n",
    "            all_preds.append(pred.cpu().numpy())\n",
    "            all_labels.append(data.y.cpu().numpy())\n",
    "            correct += int((pred == data.y.long()).sum())\n",
    "\n",
    "        accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')\n",
    "        \n",
    "        results[atlas_threshold][l_rate]['accuracy'] = accuracy\n",
    "\n",
    "        # Flatten the list of predictions and labels\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        \n",
    "        # Specify the parent folder\n",
    "        parent_folder = test_result_dir\n",
    "\n",
    "        # Specify the nested folder names\n",
    "        nested_folder1 = atlas_threshold\n",
    "        nested_folder2 = 'learning_rate_'+l_rate\n",
    "        \n",
    "        # Combine the parent and nested folder pa'hs\n",
    "        validation_result_dir = os.path.join(parent_folder, nested_folder1, nested_folder2)\n",
    "        \n",
    "        # Create the nested folders, including any necessary parent directories\n",
    "        os.makedirs(validation_result_dir, exist_ok=True)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, cmap='Blues', fmt=\".2%\")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix (Normalized)')\n",
    "        \n",
    "        # Save the image inside the nested folder\n",
    "        plt.savefig(os.path.join(validation_result_dir, 'confusion_matrix.png'))\n",
    "        \n",
    "        # Print actual vs predicted\n",
    "        actual_vs_predicted = pd.DataFrame({'Actual': all_labels, 'Predicted': all_preds})\n",
    "        print(actual_vs_predicted)\n",
    "\n",
    "        # Classification report\n",
    "        report = classification_report(all_labels, all_preds, target_names=['Non-Autistic', 'Autistic'], output_dict=True)\n",
    "        #print(classification_report(all_labels, all_preds, target_names=['Non-Autistic', 'Autistic']))\n",
    "        report_text = classification_report(all_labels, all_preds, target_names=['Non-Autistic', 'Autistic'])\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.text(0.01, 0.05, report_text, {'fontsize': 12}, fontproperties='monospace') # Adjust text size and position accordingly\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(validation_result_dir, 'classification_report.png'))\n",
    "        \n",
    "        with open(os.path.join(validation_result_dir, 'classification_report.txt'), 'w') as file:\n",
    "            file.write(report_text)\n",
    "  \n",
    "        # Individual class metrics\n",
    "        # Access individual values\n",
    "        non_autistic_precision = report['Non-Autistic']['precision']\n",
    "        autistic_precision = report['Autistic']['precision']\n",
    "\n",
    "        non_autistic_recall = report['Non-Autistic']['recall']\n",
    "        autistic_recall = report['Autistic']['recall']\n",
    "\n",
    "        non_autistic_f1_score = report['Non-Autistic']['f1-score']\n",
    "        autistic_f1_score = report['Autistic']['f1-score']\n",
    "\n",
    "        non_autistic_support = report['Non-Autistic']['support']\n",
    "        autistic_support = report['Autistic']['support']\n",
    "\n",
    "        '''# Aggregated metrics\n",
    "        accuracy = report['accuracy'''\n",
    "\n",
    "        macro_avg_precision = report['macro avg']['precision']\n",
    "        weighted_avg_precision = report['weighted avg']['precision']\n",
    "\n",
    "        macro_avg_recall = report['macro avg']['recall']\n",
    "        weighted_avg_recall = report['weighted avg']['recall']\n",
    "\n",
    "        macro_avg_f1_score = report['macro avg']['f1-score']\n",
    "        weighted_avg_f1_score = report['weighted avg']['f1-score']\n",
    "\n",
    "        macro_avg_support = report['macro avg']['support']\n",
    "        weighted_avg_support = report['weighted avg']['support']\n",
    "        \n",
    "        results[atlas_threshold][l_rate]['non_autistic_precision'] = non_autistic_precision\n",
    "        results[atlas_threshold][l_rate]['autistic_precision'] = autistic_precision\n",
    "        results[atlas_threshold][l_rate]['non_autistic_recall'] = non_autistic_recall\n",
    "        results[atlas_threshold][l_rate]['autistic_recall'] = autistic_recall\n",
    "        results[atlas_threshold][l_rate]['non_autistic_f1_score'] = non_autistic_f1_score\n",
    "        results[atlas_threshold][l_rate]['autistic_f1_score'] = autistic_f1_score\n",
    "        results[atlas_threshold][l_rate]['non_autistic_support'] = non_autistic_support\n",
    "        results[atlas_threshold][l_rate]['autistic_support'] = autistic_support\n",
    "        results[atlas_threshold][l_rate]['macro_avg_precision'] = macro_avg_precision\n",
    "        results[atlas_threshold][l_rate]['weighted_avg_precision'] = weighted_avg_precision\n",
    "        results[atlas_threshold][l_rate]['macro_avg_recall'] = macro_avg_recall\n",
    "        results[atlas_threshold][l_rate]['weighted_avg_recall'] = weighted_avg_recall\n",
    "        results[atlas_threshold][l_rate]['macro_avg_f1_score'] = macro_avg_f1_score\n",
    "        results[atlas_threshold][l_rate]['weighted_avg_f1_score'] = weighted_avg_f1_score\n",
    "        results[atlas_threshold][l_rate]['macro_avg_support'] = macro_avg_support\n",
    "        results[atlas_threshold][l_rate]['weighted_avg_support'] = weighted_avg_support\n",
    "        \n",
    "        atlas = None\n",
    "        l_rate = None\n",
    "        \n",
    "print(\"----Final Result----\")\n",
    "pprint.pprint(results)\n",
    "\n",
    "sorted_data = [(key, subkey, values['accuracy']) for key, subdata in results.items() for subkey, values in subdata.items()]\n",
    "sorted_data.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"----Sorted Accuracy----\")\n",
    "for key, subkey, accuracy in sorted_data:\n",
    "    print(f\"Key: {key}, Subkey: {subkey}, Accuracy: {accuracy}\")\n",
    "    \n",
    "# Create a list of tuples containing key, subkey, and corresponding details\n",
    "sorted_data = [(key, subkey, values) for key, subdata in results.items() for subkey, values in subdata.items()]\n",
    "\n",
    "# Sort the list based on the accuracy\n",
    "sorted_data.sort(key=lambda x: x[2]['accuracy'], reverse=True)\n",
    "\n",
    "# Create a new dictionary with the sorted order\n",
    "sorted_data_dict = {f\"{key}-{subkey}\": values for key, subkey, values in sorted_data}\n",
    "print(\"----Sorted Dict----\")\n",
    "pprint.pprint(sorted_data_dict)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
